# minGPT

![mingpt](mingpt.jpg)

PyTorch로 구현된 OpenAI GPT(특히 GPT-2) 모델의 미니멀 버전입니다. 학습(training) 및 추론(inference) 모두를 지원하며, 코드가 작고 직관적이어서 Transformer 기반 언어모델을 이해하고 실험하는 데 적합합니다.

> **참고:** 본 프로젝트는 반-아카이브(semi-archived) 상태입니다. 더 발전된 버전은 [nanoGPT](https://github.com/karpathy/nanoGPT)에서 확인할 수 있습니다.

---

## 구성 파일 및 예제

- `mingpt/model.py`: Transformer 모델 정의
- `mingpt/bpe.py`: Byte Pair Encoding 구현
- `mingpt/trainer.py`: 학습 루프 및 Trainer 클래스
- `projects/adder`: 숫자 덧셈 문제를 학습하는 GPT 예제
- `projects/chargpt`: 문자 단위 언어 모델 학습 예제
- `demo.ipynb`: 간단한 정렬 문제 예제 (노트북)
- `generate.ipynb`: 미리 학습된 GPT2로 텍스트 생성 (노트북)

---

## 설치 방법

```bash
git clone https://github.com/karpathy/minGPT.git
cd minGPT
pip install -e .
